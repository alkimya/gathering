---
phase: 05-multi-instance-production-hardening
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - gathering/api/main.py
  - gathering/api/routers/health.py
  - tests/test_graceful_shutdown.py
autonomous: true

must_haves:
  truths:
    - "During shutdown, /health/ready returns 503 with reason 'shutting_down' -- load balancer stops routing new traffic"
    - "Shutdown sequence closes async DB pool LAST (after scheduler stop and executor pause) -- no 'pool closed' errors for in-flight requests"
    - "Scheduler stops FIRST in shutdown sequence -- no new tasks created during drain period"
    - "/health/ready returns 200 during normal operation -- no false negatives"
  artifacts:
    - path: "gathering/api/routers/health.py"
      provides: "Shutdown-aware readiness probe"
      contains: "set_shutting_down"
    - path: "gathering/api/main.py"
      provides: "Reordered shutdown sequence"
      contains: "set_shutting_down"
    - path: "tests/test_graceful_shutdown.py"
      provides: "Graceful shutdown tests"
      contains: "test_readiness_probe_returns_503"
  key_links:
    - from: "gathering/api/main.py"
      to: "gathering/orchestration/scheduler.py"
      via: "get_scheduler(async_db=async_db_instance) passes async DB pool to scheduler for advisory locks"
      pattern: "get_scheduler.*async_db"
    - from: "gathering/api/main.py"
      to: "gathering/api/routers/health.py"
      via: "set_shutting_down() called at start of lifespan shutdown"
      pattern: "set_shutting_down"
    - from: "gathering/api/routers/health.py"
      to: "/health/ready endpoint"
      via: "_shutting_down flag checked in readiness_check"
      pattern: "_shutting_down"
---

<objective>
Implement graceful shutdown with ordered subsystem teardown and a shutdown-aware readiness probe so rolling deploys produce zero 502/503 errors.

Purpose: During a rolling deploy, the load balancer must stop sending traffic before subsystems close. The readiness probe (`/health/ready`) signals this. The shutdown sequence must close subsystems in the correct order: scheduler first (stop creating work), executor second (finish in-flight work), async DB pool last (keep DB available for draining requests).

Output: Shutdown-aware `/health/ready`, reordered lifespan shutdown, and tests proving correct behavior.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-multi-instance-production-hardening/05-RESEARCH.md
@gathering/api/main.py
@gathering/api/routers/health.py
@gathering/orchestration/scheduler.py
@gathering/orchestration/background.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add shutdown-aware readiness probe and reorder lifespan shutdown</name>
  <files>gathering/api/routers/health.py, gathering/api/main.py</files>
  <action>
**1. Update `gathering/api/routers/health.py`:**

Add a module-level shutdown flag and setter function:

```python
# Shutdown state for readiness probe
_shutting_down = False

def set_shutting_down():
    """Signal that the server is shutting down.

    Called from lifespan shutdown. Once set, /health/ready returns 503
    so load balancers stop routing new traffic.
    """
    global _shutting_down
    _shutting_down = True

def reset_shutting_down():
    """Reset shutdown flag (for test isolation only)."""
    global _shutting_down
    _shutting_down = False
```

Modify the existing `readiness_check` endpoint to check the flag:

```python
@router.get("/ready")
@limiter.limit(TIER_HEALTH)
async def readiness_check(request: Request):
    """Readiness probe for Kubernetes.

    Returns 200 during normal operation.
    Returns 503 during shutdown so load balancers stop routing traffic.
    """
    if _shutting_down:
        return JSONResponse(
            status_code=503,
            content={"ready": False, "reason": "shutting_down"},
        )
    return {"ready": True}
```

Add the `JSONResponse` import from `starlette.responses` if not already present.

**2. Reorder STARTUP sequence in `gathering/api/main.py`:**

Move the async database pool initialization BEFORE the scheduler start so we can pass `async_db` to `get_scheduler()`. Currently the startup order is: scheduler -> async_db. Change to: async_db -> scheduler (with async_db wired in).

Move the existing "Initialize async database pool" block (lines ~98-105 in current code) to BEFORE the "Initialize and start the scheduler" block. Then update the scheduler initialization to pass `async_db`:

```python
    # Initialize async database pool (must be before scheduler for advisory locks)
    async_db_instance = None
    try:
        from gathering.api.async_db import AsyncDatabaseService
        async_db = AsyncDatabaseService.get_instance()
        await async_db.startup()
        async_db_instance = async_db
        print("Async database pool opened")
    except Exception as e:
        print(f"Warning: Could not initialize async database pool: {e}")

    # Initialize and start the scheduler
    try:
        db = get_database_service()
        scheduler = get_scheduler(db_service=db, async_db=async_db_instance)
        await scheduler.start()
        print("Scheduler started")
    except Exception as e:
        print(f"Warning: Could not start scheduler: {e}")
```

Key changes from current startup:
- MOVE: async DB pool init happens BEFORE scheduler start (was after)
- ADD: `async_db=async_db_instance` passed to `get_scheduler()` — this activates advisory lock coordination from Plan 01
- The `async_db_instance` variable defaults to None so if pool init fails, scheduler still works in single-instance mode (graceful degradation)

**3. Reorder SHUTDOWN sequence in `gathering/api/main.py`:**

Replace the entire shutdown section (after `yield`) with this sequence:

```python
    # Shutdown
    print("GatheRing API shutting down...")

    # 1. Signal health probes that we're shutting down
    #    Load balancer will stop routing new traffic
    from gathering.api.routers.health import set_shutting_down
    set_shutting_down()

    # 2. Brief pause to let load balancer detect unhealthy state
    import asyncio as _asyncio
    await _asyncio.sleep(3)

    # 3. Stop the scheduler FIRST (prevent new task creation)
    #    Note: scheduler.stop() cancels the main loop task, but in-flight
    #    _execute_action calls spawned via asyncio.create_task() may still
    #    be running advisory lock queries against the async DB pool.
    try:
        scheduler = get_scheduler()
        await scheduler.stop(timeout=10)
        print("Scheduler stopped")
    except Exception as e:
        print(f"Warning: Error during scheduler shutdown: {e}")

    # 4. Brief drain for in-flight scheduler _execute_action tasks
    #    scheduler.stop() cancels the loop but fire-and-forget tasks from
    #    asyncio.create_task(_execute_action(...)) may still hold advisory
    #    lock queries. Give them time to complete before closing the DB pool.
    await _asyncio.sleep(2)

    # 5. Gracefully shutdown background task executor (pause running tasks)
    try:
        executor = get_background_executor()
        await executor.shutdown(timeout=30)
        print("Background task executor shutdown complete")
    except Exception as e:
        print(f"Warning: Error during background executor shutdown: {e}")

    # 6. Close async database pool LAST
    #    In-flight requests may still need DB access during drain period
    try:
        from gathering.api.async_db import AsyncDatabaseService
        if AsyncDatabaseService._instance is not None:
            await AsyncDatabaseService.get_instance().shutdown()
            print("Async database pool closed")
    except Exception as e:
        print(f"Warning: Error during async database pool shutdown: {e}")
```

Key changes from current code:
- ADD: `set_shutting_down()` call at start
- ADD: `await asyncio.sleep(3)` for LB drain (step 2)
- REORDER: Scheduler stops FIRST (was second), then drain sleep for in-flight tasks, then executor, then async DB pool LAST (was first)
- ADD: `await asyncio.sleep(2)` after scheduler.stop() (step 4) — drains in-flight `_execute_action` tasks that may hold advisory lock queries against the async DB pool. Without this, closing the pool could interrupt active lock queries.
- The `import asyncio as _asyncio` avoids shadowing the module-level `asyncio` import if present. If `asyncio` is already imported at module level, use that instead.

Also add `asyncio` to the imports at the top of main.py if not already imported.
  </action>
  <verify>
```bash
python -c "from gathering.api.main import app; print('App imports OK')"
python -c "from gathering.api.routers.health import set_shutting_down, reset_shutting_down; print('Health imports OK')"
```
Both imports succeed without errors.
  </verify>
  <done>Readiness probe returns 503 during shutdown. Startup sequence moves async DB pool init before scheduler and passes async_db to get_scheduler(). Shutdown sequence is: set_shutting_down -> sleep(3) -> stop scheduler -> sleep(2) drain for in-flight tasks -> pause executor -> close async DB pool. Imports clean.</done>
</task>

<task type="auto">
  <name>Task 2: Add graceful shutdown tests</name>
  <files>tests/test_graceful_shutdown.py</files>
  <action>
Create `tests/test_graceful_shutdown.py` with tests proving shutdown behavior:

1. **test_readiness_probe_returns_200_normally:**
   Use `httpx.AsyncClient` with `ASGITransport(app=app)` (or `TestClient`) to call `GET /health/ready`. Assert 200 and `{"ready": True}`.
   Call `reset_shutting_down()` in setup/teardown for test isolation.

2. **test_readiness_probe_returns_503_during_shutdown:**
   Import `set_shutting_down` and `reset_shutting_down` from health module. Call `set_shutting_down()`. Then `GET /health/ready`. Assert status 503 and response body `{"ready": False, "reason": "shutting_down"}`. Call `reset_shutting_down()` in teardown.

3. **test_shutdown_sequence_order:**
   Verify the lifespan shutdown calls subsystems in correct order. This is a unit test of the shutdown logic:
   - Create a list to record call order
   - Mock `set_shutting_down` to append "set_shutting_down"
   - Mock `asyncio.sleep` to record each call with its argument: append `f"sleep({args[0]})"` (and return immediately)
   - Mock `get_scheduler().stop()` to append "scheduler_stop"
   - Mock `get_background_executor().shutdown()` to append "executor_shutdown"
   - Mock `AsyncDatabaseService.get_instance().shutdown()` to append "async_db_shutdown"
   - Run the lifespan context manager (enter and exit)
   - Assert order is: ["set_shutting_down", "sleep(3)", "scheduler_stop", "sleep(2)", "executor_shutdown", "async_db_shutdown"]
   - The sleep(3) is the LB drain pause; sleep(2) is the in-flight task drain after scheduler stop (advisory lock queries may still be running)

   Note: The lifespan startup has side effects (scheduler start, DB pool open). Mock all startup calls too to prevent real initialization. Use `unittest.mock.patch` on each subsystem's startup path.

4. **test_set_shutting_down_is_idempotent:**
   Call `set_shutting_down()` twice. Then check `GET /health/ready` returns 503. No crash on double-call. Call `reset_shutting_down()` in teardown.

5. **test_reset_shutting_down_restores_readiness:**
   Call `set_shutting_down()`, verify 503, call `reset_shutting_down()`, verify 200 again.

For HTTP tests, use the FastAPI `TestClient` from `starlette.testclient` (sync) or `httpx.AsyncClient` with `ASGITransport`. Since the health endpoints don't need auth in tests, create the app with `enable_auth=False`.

Important: Always call `reset_shutting_down()` in test teardown to prevent state leaking between tests. Use `pytest.fixture(autouse=True)` or explicit cleanup.
  </action>
  <verify>
```bash
python -m pytest tests/test_graceful_shutdown.py -x -q -v
```
All 5 tests pass.
  </verify>
  <done>5 graceful shutdown tests pass, proving: readiness 200 normally, 503 during shutdown, correct shutdown order, idempotent flag setting, and flag reset restores readiness.</done>
</task>

</tasks>

<verification>
- `python -m pytest tests/test_graceful_shutdown.py -x -q -v` -- all pass
- `grep -n "async_db" gathering/api/main.py` -- confirms async_db passed to get_scheduler() in startup
- `grep -n "set_shutting_down" gathering/api/main.py` -- confirms flag set during shutdown
- `grep -n "_shutting_down" gathering/api/routers/health.py` -- confirms flag checked in readiness probe
- Verify startup order in main.py: async_db.startup() -> get_scheduler(async_db=async_db_instance)
- Verify shutdown order in main.py: set_shutting_down -> sleep(3) -> scheduler.stop -> sleep(2) drain -> executor.shutdown -> async_db.shutdown
</verification>

<success_criteria>
- /health/ready returns 200 normally, 503 during shutdown with {"ready": False, "reason": "shutting_down"}
- Startup sequence: async_db pool init -> get_scheduler(async_db=async_db_instance) -> scheduler.start() (async_db initialized BEFORE scheduler so advisory locks are wired)
- Shutdown sequence: set_shutting_down() -> sleep(3) -> scheduler.stop() -> sleep(2) drain -> executor.shutdown() -> async_db.shutdown()
- Async DB pool closes LAST (not first as before) -- in-flight advisory lock queries from _execute_action tasks have time to complete
- Scheduler stops FIRST in teardown (no new task creation during drain)
- All 5 tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/05-multi-instance-production-hardening/05-02-SUMMARY.md`
</output>
