---
phase: 05-multi-instance-production-hardening
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - gathering/api/main.py
  - gathering/api/routers/health.py
  - tests/test_graceful_shutdown.py
autonomous: true

must_haves:
  truths:
    - "During shutdown, /health/ready returns 503 with reason 'shutting_down' -- load balancer stops routing new traffic"
    - "Shutdown sequence closes async DB pool LAST (after scheduler stop and executor pause) -- no 'pool closed' errors for in-flight requests"
    - "Scheduler stops FIRST in shutdown sequence -- no new tasks created during drain period"
    - "/health/ready returns 200 during normal operation -- no false negatives"
  artifacts:
    - path: "gathering/api/routers/health.py"
      provides: "Shutdown-aware readiness probe"
      contains: "set_shutting_down"
    - path: "gathering/api/main.py"
      provides: "Reordered shutdown sequence"
      contains: "set_shutting_down"
    - path: "tests/test_graceful_shutdown.py"
      provides: "Graceful shutdown tests"
      contains: "test_readiness_probe_returns_503"
  key_links:
    - from: "gathering/api/main.py"
      to: "gathering/api/routers/health.py"
      via: "set_shutting_down() called at start of lifespan shutdown"
      pattern: "set_shutting_down"
    - from: "gathering/api/routers/health.py"
      to: "/health/ready endpoint"
      via: "_shutting_down flag checked in readiness_check"
      pattern: "_shutting_down"
---

<objective>
Implement graceful shutdown with ordered subsystem teardown and a shutdown-aware readiness probe so rolling deploys produce zero 502/503 errors.

Purpose: During a rolling deploy, the load balancer must stop sending traffic before subsystems close. The readiness probe (`/health/ready`) signals this. The shutdown sequence must close subsystems in the correct order: scheduler first (stop creating work), executor second (finish in-flight work), async DB pool last (keep DB available for draining requests).

Output: Shutdown-aware `/health/ready`, reordered lifespan shutdown, and tests proving correct behavior.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-multi-instance-production-hardening/05-RESEARCH.md
@gathering/api/main.py
@gathering/api/routers/health.py
@gathering/orchestration/scheduler.py
@gathering/orchestration/background.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add shutdown-aware readiness probe and reorder lifespan shutdown</name>
  <files>gathering/api/routers/health.py, gathering/api/main.py</files>
  <action>
**1. Update `gathering/api/routers/health.py`:**

Add a module-level shutdown flag and setter function:

```python
# Shutdown state for readiness probe
_shutting_down = False

def set_shutting_down():
    """Signal that the server is shutting down.

    Called from lifespan shutdown. Once set, /health/ready returns 503
    so load balancers stop routing new traffic.
    """
    global _shutting_down
    _shutting_down = True

def reset_shutting_down():
    """Reset shutdown flag (for test isolation only)."""
    global _shutting_down
    _shutting_down = False
```

Modify the existing `readiness_check` endpoint to check the flag:

```python
@router.get("/ready")
@limiter.limit(TIER_HEALTH)
async def readiness_check(request: Request):
    """Readiness probe for Kubernetes.

    Returns 200 during normal operation.
    Returns 503 during shutdown so load balancers stop routing traffic.
    """
    if _shutting_down:
        return JSONResponse(
            status_code=503,
            content={"ready": False, "reason": "shutting_down"},
        )
    return {"ready": True}
```

Add the `JSONResponse` import from `starlette.responses` if not already present.

**2. Reorder shutdown sequence in `gathering/api/main.py`:**

Replace the entire shutdown section (after `yield`) with this sequence:

```python
    # Shutdown
    print("GatheRing API shutting down...")

    # 1. Signal health probes that we're shutting down
    #    Load balancer will stop routing new traffic
    from gathering.api.routers.health import set_shutting_down
    set_shutting_down()

    # 2. Brief pause to let load balancer detect unhealthy state
    import asyncio as _asyncio
    await _asyncio.sleep(3)

    # 3. Stop the scheduler FIRST (prevent new task creation)
    try:
        scheduler = get_scheduler()
        await scheduler.stop(timeout=10)
        print("Scheduler stopped")
    except Exception as e:
        print(f"Warning: Error during scheduler shutdown: {e}")

    # 4. Gracefully shutdown background task executor (pause running tasks)
    try:
        executor = get_background_executor()
        await executor.shutdown(timeout=30)
        print("Background task executor shutdown complete")
    except Exception as e:
        print(f"Warning: Error during background executor shutdown: {e}")

    # 5. Close async database pool LAST
    #    In-flight requests may still need DB access during drain period
    try:
        from gathering.api.async_db import AsyncDatabaseService
        if AsyncDatabaseService._instance is not None:
            await AsyncDatabaseService.get_instance().shutdown()
            print("Async database pool closed")
    except Exception as e:
        print(f"Warning: Error during async database pool shutdown: {e}")
```

Key changes from current code:
- ADD: `set_shutting_down()` call at start
- ADD: `await asyncio.sleep(3)` for LB drain
- REORDER: Scheduler stops FIRST (was second), then executor, then async DB pool LAST (was first)
- The `import asyncio as _asyncio` avoids shadowing the module-level `asyncio` import if present. If `asyncio` is already imported at module level, use that instead.

Also add `asyncio` to the imports at the top of main.py if not already imported.
  </action>
  <verify>
```bash
python -c "from gathering.api.main import app; print('App imports OK')"
python -c "from gathering.api.routers.health import set_shutting_down, reset_shutting_down; print('Health imports OK')"
```
Both imports succeed without errors.
  </verify>
  <done>Readiness probe returns 503 during shutdown. Shutdown sequence is: set_shutting_down -> sleep(3) -> stop scheduler -> pause executor -> close async DB pool. Imports clean.</done>
</task>

<task type="auto">
  <name>Task 2: Add graceful shutdown tests</name>
  <files>tests/test_graceful_shutdown.py</files>
  <action>
Create `tests/test_graceful_shutdown.py` with tests proving shutdown behavior:

1. **test_readiness_probe_returns_200_normally:**
   Use `httpx.AsyncClient` with `ASGITransport(app=app)` (or `TestClient`) to call `GET /health/ready`. Assert 200 and `{"ready": True}`.
   Call `reset_shutting_down()` in setup/teardown for test isolation.

2. **test_readiness_probe_returns_503_during_shutdown:**
   Import `set_shutting_down` and `reset_shutting_down` from health module. Call `set_shutting_down()`. Then `GET /health/ready`. Assert status 503 and response body `{"ready": False, "reason": "shutting_down"}`. Call `reset_shutting_down()` in teardown.

3. **test_shutdown_sequence_order:**
   Verify the lifespan shutdown calls subsystems in correct order. This is a unit test of the shutdown logic:
   - Create a list to record call order
   - Mock `set_shutting_down` to append "set_shutting_down"
   - Mock `asyncio.sleep` to append "sleep" (and return immediately)
   - Mock `get_scheduler().stop()` to append "scheduler_stop"
   - Mock `get_background_executor().shutdown()` to append "executor_shutdown"
   - Mock `AsyncDatabaseService.get_instance().shutdown()` to append "async_db_shutdown"
   - Run the lifespan context manager (enter and exit)
   - Assert order is: ["set_shutting_down", "sleep", "scheduler_stop", "executor_shutdown", "async_db_shutdown"]

   Note: The lifespan startup has side effects (scheduler start, DB pool open). Mock all startup calls too to prevent real initialization. Use `unittest.mock.patch` on each subsystem's startup path.

4. **test_set_shutting_down_is_idempotent:**
   Call `set_shutting_down()` twice. Then check `GET /health/ready` returns 503. No crash on double-call. Call `reset_shutting_down()` in teardown.

5. **test_reset_shutting_down_restores_readiness:**
   Call `set_shutting_down()`, verify 503, call `reset_shutting_down()`, verify 200 again.

For HTTP tests, use the FastAPI `TestClient` from `starlette.testclient` (sync) or `httpx.AsyncClient` with `ASGITransport`. Since the health endpoints don't need auth in tests, create the app with `enable_auth=False`.

Important: Always call `reset_shutting_down()` in test teardown to prevent state leaking between tests. Use `pytest.fixture(autouse=True)` or explicit cleanup.
  </action>
  <verify>
```bash
python -m pytest tests/test_graceful_shutdown.py -x -q -v
```
All 5 tests pass.
  </verify>
  <done>5 graceful shutdown tests pass, proving: readiness 200 normally, 503 during shutdown, correct shutdown order, idempotent flag setting, and flag reset restores readiness.</done>
</task>

</tasks>

<verification>
- `python -m pytest tests/test_graceful_shutdown.py -x -q -v` -- all pass
- `grep -n "set_shutting_down" gathering/api/main.py` -- confirms flag set during shutdown
- `grep -n "_shutting_down" gathering/api/routers/health.py` -- confirms flag checked in readiness probe
- Verify shutdown order in main.py: set_shutting_down -> sleep -> scheduler.stop -> executor.shutdown -> async_db.shutdown
</verification>

<success_criteria>
- /health/ready returns 200 normally, 503 during shutdown with {"ready": False, "reason": "shutting_down"}
- Shutdown sequence: set_shutting_down() -> sleep(3) -> scheduler.stop() -> executor.shutdown() -> async_db.shutdown()
- Async DB pool closes LAST (not first as before)
- Scheduler stops FIRST in teardown (no new task creation during drain)
- All 5 tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/05-multi-instance-production-hardening/05-02-SUMMARY.md`
</output>
