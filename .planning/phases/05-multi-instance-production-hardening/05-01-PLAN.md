---
phase: 05-multi-instance-production-hardening
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - gathering/orchestration/scheduler.py
  - tests/test_advisory_lock_scheduler.py
autonomous: true

must_haves:
  truths:
    - "Two scheduler instances competing for the same scheduled action execute it exactly once -- the loser skips silently"
    - "Advisory lock failure (DB error) causes safe skip (fail-closed) rather than duplicate execution"
    - "Scheduler without async DB (single-instance mode) continues to work unchanged -- advisory lock is additive, not required"
    - "Scheduler initialized with async_db successfully acquires and respects advisory locks -- wiring is validated by tests passing with mock async_db"
  artifacts:
    - path: "gathering/orchestration/scheduler.py"
      provides: "_try_acquire_action_lock method using pg_try_advisory_xact_lock"
      contains: "pg_try_advisory_xact_lock"
    - path: "tests/test_advisory_lock_scheduler.py"
      provides: "Advisory lock coordination tests"
      contains: "test_advisory_lock_prevents_duplicate"
  key_links:
    - from: "gathering/orchestration/scheduler.py"
      to: "AsyncDatabaseService._pool"
      via: "_try_acquire_action_lock uses async_db connection"
      pattern: "pg_try_advisory_xact_lock"
---

<objective>
Add PostgreSQL advisory lock coordination to the Scheduler so that multiple server instances processing the same scheduled_actions table never execute the same action simultaneously.

Purpose: Prevents duplicate task execution in multi-instance deployments (multiple uvicorn workers or Kubernetes pods). Each instance's scheduler loop checks the same DB table, and without coordination they would all execute every due action.

Output: Scheduler._try_acquire_action_lock() method, integration into _execute_action(), and tests proving exactly-once execution under concurrency.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-multi-instance-production-hardening/05-RESEARCH.md
@gathering/orchestration/scheduler.py
@gathering/api/async_db.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add advisory lock coordination to Scheduler</name>
  <files>gathering/orchestration/scheduler.py</files>
  <action>
Add advisory lock support to the Scheduler class:

1. **Accept optional async_db in constructor and get_scheduler():**
   - Add `async_db` parameter (type `Optional[Any]`, default `None`) to `Scheduler.__init__()`. Store as `self._async_db`.
   - Add `async_db` parameter to `get_scheduler()` factory. Pass it to the Scheduler constructor.

2. **Add `_try_acquire_action_lock` method:**
   ```python
   SCHEDULER_LOCK_NAMESPACE = 1  # Module-level constant

   async def _try_acquire_action_lock(self, action_id: int) -> bool:
       """Try to acquire a transaction-scoped advisory lock for a scheduled action.

       Uses pg_try_advisory_xact_lock(namespace, action_id) which:
       - Returns True if lock acquired, False if another session holds it
       - Auto-releases on transaction COMMIT/ROLLBACK (no leaked locks)
       - Is non-blocking (returns immediately, never waits)

       Returns True (proceed) if:
       - Lock acquired successfully
       - No async_db available (single-instance mode, always proceed)

       Returns False (skip) if:
       - Another instance holds the lock
       - DB error during lock attempt (fail-closed for safety)
       """
   ```
   Implementation: If `self._async_db` is None, return True (backward compat). Otherwise, use `self._async_db._pool.connection()` context manager to get a raw async connection, open a transaction, execute `SELECT pg_try_advisory_xact_lock(%s, %s) AS acquired` with params `[SCHEDULER_LOCK_NAMESPACE, action_id]`, fetch the row, return `row["acquired"]`. Wrap in try/except: on any exception, log warning and return False (fail-closed -- skip rather than risk duplicate).

3. **Integrate lock check into `_execute_action`:**
   At the very start of `_execute_action`, before the existing `async with self._lock:` block, add:
   ```python
   lock_acquired = await self._try_acquire_action_lock(action_id)
   if not lock_acquired:
       logger.debug("Action %s locked by another instance, skipping", action_id)
       # Remove from _running_actions since we won't execute
       async with self._lock:
           self._running_actions.discard(action_id)
       return
   ```
   This goes BEFORE the existing concurrency check so the advisory lock is the first gate.

4. **Wire async_db in lifespan (gathering/api/main.py):**
   Do NOT modify main.py in this task (Plan 02 handles lifespan changes). The async_db will be passed to get_scheduler() once the lifespan is reordered. For now, the Scheduler accepts it as an optional parameter and works without it.

Important: Use the two-integer form `pg_try_advisory_xact_lock(%s, %s)` with positional params (psycopg 3 uses %s, not %(name)s, for raw connections). The namespace constant (1) prevents collision with other advisory lock users.
  </action>
  <verify>
Run existing scheduler tests to confirm no regressions:
```bash
python -m pytest tests/test_scheduler_dispatch.py tests/test_scheduler_recovery.py -x -q
```
All existing tests must pass since async_db defaults to None (single-instance mode, lock always returns True).
  </verify>
  <done>Scheduler has _try_acquire_action_lock method. _execute_action checks advisory lock before proceeding. Single-instance mode (no async_db) unchanged. Existing tests pass.</done>
</task>

<task type="auto">
  <name>Task 2: Add advisory lock coordination tests</name>
  <files>tests/test_advisory_lock_scheduler.py</files>
  <action>
Create `tests/test_advisory_lock_scheduler.py` with tests proving advisory lock behavior:

1. **test_try_acquire_lock_no_async_db_returns_true:**
   Create a Scheduler with `async_db=None`. Call `_try_acquire_action_lock(42)`. Assert returns True (single-instance always proceeds).

2. **test_try_acquire_lock_db_error_returns_false:**
   Create a mock async_db whose `_pool.connection()` raises an Exception. Call `_try_acquire_action_lock(42)`. Assert returns False (fail-closed).

3. **test_advisory_lock_prevents_duplicate_execution:**
   Simulate two concurrent `_execute_action` calls for the same action. Mock `_try_acquire_action_lock` to return True on first call, False on second. Verify the action handler (dispatched via ACTION_DISPATCHERS) is called exactly once.

   Setup:
   - Create a Scheduler with mock db_service and event_bus
   - Create a ScheduledAction with id=42, action_type="run_task"
   - Patch `_try_acquire_action_lock` with a side_effect that returns True first, then False
   - Patch the run_task dispatcher to record calls
   - Call `_execute_action(action)` twice concurrently with `asyncio.gather`
   - Assert the dispatcher was called exactly once

4. **test_lock_skip_removes_from_running_actions:**
   When advisory lock returns False, verify the action_id is removed from `_running_actions` set. Create a Scheduler, add action_id to `_running_actions`, mock `_try_acquire_action_lock` to return False, call `_execute_action`. Assert action_id NOT in `_running_actions` after call.

5. **test_execute_action_with_lock_success_proceeds:**
   Mock `_try_acquire_action_lock` to return True. Call `_execute_action` with a valid action. Assert the dispatcher was called and action's `execution_count` incremented.

Use `pytest.mark.asyncio` on all tests. Mock the DB service and event_bus (no real DB connection needed). Use `unittest.mock.AsyncMock` for async methods.
  </action>
  <verify>
```bash
python -m pytest tests/test_advisory_lock_scheduler.py -x -q -v
```
All 5 tests pass.
  </verify>
  <done>5 advisory lock tests pass, proving: single-instance bypass, fail-closed on DB error, exactly-once execution, cleanup on skip, and normal execution with lock.</done>
</task>

</tasks>

<verification>
- `python -m pytest tests/test_advisory_lock_scheduler.py tests/test_scheduler_dispatch.py tests/test_scheduler_recovery.py -x -q` -- all pass
- `grep -n "pg_try_advisory_xact_lock" gathering/orchestration/scheduler.py` -- confirms advisory lock SQL present
- `grep -n "SCHEDULER_LOCK_NAMESPACE" gathering/orchestration/scheduler.py` -- confirms namespace constant
</verification>

<success_criteria>
- Scheduler._try_acquire_action_lock() uses pg_try_advisory_xact_lock with two-integer form (namespace, action_id)
- _execute_action checks advisory lock before any execution logic
- No async_db = single instance mode, all locks return True (backward compatible)
- DB error during lock = returns False (fail-closed, skip execution)
- All existing scheduler tests pass unchanged
- 5 new tests prove advisory lock behavior
</success_criteria>

<output>
After completion, create `.planning/phases/05-multi-instance-production-hardening/05-01-SUMMARY.md`
</output>
