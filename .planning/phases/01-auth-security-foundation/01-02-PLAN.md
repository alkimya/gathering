---
phase: 01-auth-security-foundation
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - gathering/api/auth.py
  - gathering/api/routers/auth.py
  - gathering/api/dependencies.py
  - gathering/api/middleware.py
autonomous: true

must_haves:
  truths:
    - "A user created via POST /auth/register exists in PostgreSQL auth.users table and survives server restart"
    - "Login after restart succeeds with the same credentials used to register"
    - "A revoked token remains rejected after server restart -- blacklist is persisted to auth.token_blacklist"
    - "Auth endpoints respond in constant time regardless of whether the email exists"
    - "Auth events (login success, login failure, registration, logout, token revocation reuse) are logged to audit.security_events"
  artifacts:
    - path: "gathering/api/auth.py"
      provides: "DB-backed user CRUD, TokenBlacklist class, constant-time authenticate_user, audit event logging"
      contains: "class TokenBlacklist"
    - path: "gathering/api/routers/auth.py"
      provides: "Auth endpoints wired to DatabaseService for persistence"
      contains: "db: DatabaseService"
    - path: "gathering/api/dependencies.py"
      provides: "DatabaseService used by auth functions"
      contains: "class DatabaseService"
    - path: "gathering/api/middleware.py"
      provides: "Auth middleware with constant-time responses and audit logging on failures"
      contains: "log_auth_event"
  key_links:
    - from: "gathering/api/auth.py"
      to: "gathering/api/dependencies.py"
      via: "DatabaseService passed to user CRUD and TokenBlacklist"
      pattern: "db.*DatabaseService"
    - from: "gathering/api/auth.py"
      to: "auth.users table"
      via: "SQL queries with parameterized statements"
      pattern: "FROM auth\\.users"
    - from: "gathering/api/auth.py"
      to: "auth.token_blacklist table"
      via: "TokenBlacklist class write-through to DB"
      pattern: "auth\\.token_blacklist"
    - from: "gathering/api/auth.py"
      to: "audit.security_events table"
      via: "log_auth_event function"
      pattern: "audit\\.security_events"
    - from: "gathering/api/routers/auth.py"
      to: "gathering/api/auth.py"
      via: "Function calls with db parameter"
      pattern: "authenticate_user.*db"
---

<objective>
Replace in-memory auth storage with PostgreSQL persistence -- users stored in auth.users, token blacklist backed by auth.token_blacklist with in-memory LRU cache, audit events written to audit.security_events. Make authenticate_user constant-time regardless of email existence.

Purpose: This is the core deliverable of Phase 1 -- auth that survives restarts. Success criteria #1 (user persistence), #2 (token blacklist persistence), and #4 (constant-time auth) are satisfied by this plan.

Output: Fully persistent auth system with audit trail. In-memory stores (_users_store, _token_blacklist dict) replaced with database-backed implementations.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-auth-security-foundation/01-RESEARCH.md
@.planning/phases/01-auth-security-foundation/01-01-SUMMARY.md

@gathering/api/auth.py
@gathering/api/routers/auth.py
@gathering/api/dependencies.py
@gathering/api/middleware.py
@gathering/db/migrations/006_auth_users.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Database-backed user CRUD and TokenBlacklist class</name>
  <files>
    gathering/api/auth.py
    gathering/api/dependencies.py
  </files>
  <action>
    **Step 1: Run the auth migration against the development database.**

    Execute the migration SQL to create the auth tables:
    ```bash
    cd /home/loc/workspace/gathering
    # Use the project's migration runner or psql directly
    python -c "
    from gathering.api.dependencies import DatabaseService
    db = DatabaseService()
    with open('gathering/db/migrations/006_auth_users.sql') as f:
        sql = f.read()
    # Execute each statement (split on semicolons, skip empty)
    for stmt in sql.split(';'):
        stmt = stmt.strip()
        if stmt and not stmt.startswith('--'):
            try:
                db.execute(stmt)
            except Exception as e:
                print(f'Note: {e}')
    print('Migration complete')
    "
    ```
    If the project has a migration runner (check `pycopg.Migrator`), prefer that. Otherwise use the above approach or `psql -f gathering/db/migrations/006_auth_users.sql`.

    **Step 2: Add audit event logging function to gathering/api/auth.py.**

    Add near the top of the file (after imports), a function to log security events:

    ```python
    import json
    import logging

    logger = logging.getLogger(__name__)

    def log_auth_event(
        db,
        event_type: str,
        user_id: Optional[str] = None,
        ip_address: Optional[str] = None,
        message: str = "",
        details: Optional[dict] = None,
        severity: str = "info",
    ) -> None:
        """Log authentication event to audit.security_events table.

        Fails silently (logs warning) to avoid blocking auth operations.
        """
        try:
            db.execute(
                "INSERT INTO audit.security_events "
                "(event_type, severity, user_id, ip_address, message, details) "
                "VALUES (%(event_type)s, %(severity)s, %(user_id)s, "
                "%(ip_address)s::inet, %(message)s, %(details)s::jsonb)",
                {
                    "event_type": event_type,
                    "severity": severity,
                    "user_id": user_id,
                    "ip_address": ip_address or "0.0.0.0",
                    "message": message,
                    "details": json.dumps(details or {}),
                }
            )
        except Exception as e:
            logger.warning(f"Failed to log auth event: {e}")
    ```

    **Step 3: Replace in-memory user store with database-backed functions.**

    Remove `_users_store: dict[str, dict] = {}` entirely.

    Replace `get_user_by_email()`:
    ```python
    async def get_user_by_email(email: str, db=None) -> Optional[dict]:
        """Get user by email from database."""
        if db is None:
            db = DatabaseService.get_instance()
        result = db.execute_one(
            "SELECT external_id as id, email, name, password_hash, role, is_active, created_at "
            "FROM auth.users WHERE email_lower = %(email)s",
            {"email": email.lower()}
        )
        return result
    ```

    Replace `get_user_by_id()`:
    ```python
    async def get_user_by_id(user_id: str, db=None) -> Optional[dict]:
        """Get user by external ID from database."""
        if db is None:
            db = DatabaseService.get_instance()
        result = db.execute_one(
            "SELECT external_id as id, email, name, password_hash, role, is_active, created_at "
            "FROM auth.users WHERE external_id = %(user_id)s",
            {"user_id": user_id}
        )
        return result
    ```

    Replace `create_user()`:
    ```python
    async def create_user(user_data: UserCreate, db=None) -> dict:
        """Create a new user in the database."""
        if db is None:
            db = DatabaseService.get_instance()
        result = db.execute_one(
            "INSERT INTO auth.users (email, name, password_hash, role, is_active) "
            "VALUES (%(email)s, %(name)s, %(password_hash)s, 'user', TRUE) "
            "RETURNING external_id as id, email, name, role, is_active, created_at",
            {
                "email": user_data.email,
                "name": user_data.name,
                "password_hash": get_password_hash(user_data.password),
            }
        )
        return result
    ```

    Add `DatabaseService` import at top: `from gathering.api.dependencies import DatabaseService`

    **Step 4: Add singleton accessor to DatabaseService in gathering/api/dependencies.py.**

    If not already present, add a `get_instance()` classmethod:
    ```python
    @classmethod
    def get_instance(cls) -> 'DatabaseService':
        """Get or create the singleton DatabaseService instance."""
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance
    ```

    **Step 5: Replace in-memory token blacklist with TokenBlacklist class.**

    Remove the module-level `_token_blacklist`, `_blacklist_cleanup_interval`, `_last_cleanup` variables.

    Add the `TokenBlacklist` class:
    ```python
    class TokenBlacklist:
        """Two-layer token blacklist: in-memory LRU cache backed by PostgreSQL.

        The cache provides sub-millisecond lookups for hot tokens.
        The database ensures blacklist survives server restarts.
        Write-through: every blacklist addition writes to both layers.
        """

        _instance: Optional['TokenBlacklist'] = None

        def __init__(self, db=None, cache_max_size: int = 10000):
            from collections import OrderedDict
            self._db = db
            self._cache: OrderedDict[str, float] = OrderedDict()
            self._cache_max_size = cache_max_size

        @classmethod
        def get_instance(cls, db=None) -> 'TokenBlacklist':
            if cls._instance is None:
                cls._instance = cls(db=db or DatabaseService.get_instance())
            return cls._instance

        def _get_db(self):
            if self._db is None:
                self._db = DatabaseService.get_instance()
            return self._db

        def blacklist(self, token_hash: str, expires_at: float, user_id: str = None, reason: str = "logout") -> None:
            """Add token to blacklist (write-through to cache and DB)."""
            # Write to cache
            self._cache[token_hash] = expires_at
            if len(self._cache) > self._cache_max_size:
                self._cache.popitem(last=False)

            # Write to DB
            try:
                self._get_db().execute(
                    "INSERT INTO auth.token_blacklist (token_hash, expires_at, user_id, reason) "
                    "VALUES (%(hash)s, to_timestamp(%(exp)s), %(user_id)s, %(reason)s) "
                    "ON CONFLICT (token_hash) DO NOTHING",
                    {"hash": token_hash, "exp": expires_at, "user_id": user_id, "reason": reason}
                )
            except Exception as e:
                logger.warning(f"Failed to persist token blacklist entry: {e}")

        def is_blacklisted(self, token_hash: str) -> bool:
            """Check if token is blacklisted. Cache first, then DB fallback."""
            now = datetime.now(timezone.utc).timestamp()

            # Check cache
            if token_hash in self._cache:
                exp = self._cache[token_hash]
                if exp > now:
                    return True
                else:
                    del self._cache[token_hash]
                    return False

            # Check DB
            try:
                result = self._get_db().execute_one(
                    "SELECT EXTRACT(EPOCH FROM expires_at) as exp "
                    "FROM auth.token_blacklist "
                    "WHERE token_hash = %(hash)s AND expires_at > NOW()",
                    {"hash": token_hash}
                )
                if result:
                    # Promote to cache
                    self._cache[token_hash] = float(result["exp"])
                    if len(self._cache) > self._cache_max_size:
                        self._cache.popitem(last=False)
                    return True
            except Exception as e:
                logger.warning(f"Failed to check token blacklist in DB: {e}")

            return False

        def get_stats(self) -> dict:
            """Get blacklist statistics."""
            try:
                db_count = self._get_db().execute_one(
                    "SELECT COUNT(*) as count FROM auth.token_blacklist WHERE expires_at > NOW()"
                )
                db_total = db_count["count"] if db_count else 0
            except Exception:
                db_total = "unknown"

            return {
                "cache_size": len(self._cache),
                "cache_max_size": self._cache_max_size,
                "db_active_tokens": db_total,
            }
    ```

    **Step 6: Update blacklist_token(), is_token_blacklisted(), get_blacklist_stats() to use TokenBlacklist.**

    ```python
    def blacklist_token(token: str, user_id: str = None) -> bool:
        """Add a token to the blacklist (for logout)."""
        try:
            payload = jwt.decode(token, get_secret_key(), algorithms=[ALGORITHM])
            exp = payload.get("exp", 0)
            now = datetime.now(timezone.utc).timestamp()
            if exp > now:
                token_hash = _get_token_hash(token)
                TokenBlacklist.get_instance().blacklist(token_hash, exp, user_id=user_id)
            return True
        except PyJWTError:
            return False

    def is_token_blacklisted(token: str) -> bool:
        """Check if a token is blacklisted."""
        token_hash = _get_token_hash(token)
        return TokenBlacklist.get_instance().is_blacklisted(token_hash)

    def get_blacklist_stats() -> dict:
        """Get statistics about the token blacklist."""
        return TokenBlacklist.get_instance().get_stats()
    ```

    **Step 7: Make authenticate_user() constant-time.**

    Replace the current `authenticate_user()` with a constant-time version per the research pattern:
    ```python
    async def authenticate_user(email: str, password: str, db=None) -> Optional[dict]:
        """Authenticate a user by email and password.
        Checks admin credentials first, then database users.
        Uses constant-time operations to prevent timing attacks.
        """
        if db is None:
            db = DatabaseService.get_instance()

        # Check admin first (already constant-time)
        admin = verify_admin_credentials(email, password)
        if admin:
            log_auth_event(db, "auth_success", user_id="admin", message=f"Admin login: {email}")
            return {"id": admin.id, "email": admin.email, "name": admin.name, "role": admin.role}

        # Always query database (even if we'll fail -- constant time)
        user = await get_user_by_email(email, db)

        # Always verify password (use dummy hash if user not found -- constant time)
        dummy_hash = "$2b$12$LQv3c1yqBWVHxkd0LHAkCOYz6TtxMQJqhN8/X4.VTtYWWQIe0u0S."
        stored_hash = user.get("password_hash", "") if user else dummy_hash

        password_valid = verify_password(password, stored_hash)

        if user and password_valid and user.get("is_active", False):
            log_auth_event(db, "auth_success", user_id=user["id"], message=f"User login: {email}")
            return {
                "id": user["id"],
                "email": user["email"],
                "name": user.get("name", ""),
                "role": user.get("role", "user"),
            }

        # Log failure (don't reveal which part failed)
        log_auth_event(db, "auth_failure", message=f"Failed login attempt for: {email}", severity="warning")
        return None
    ```

    **CRITICAL constraints:**
    - User ID format remains `str` (external_id from auth.users is VARCHAR(36) UUID string)
    - EventBus is NOT touched -- no changes to event system
    - dummy_hash ensures bcrypt.checkpw always runs even when user not found
  </action>
  <verify>
    Run `pytest tests/test_auth.py -v` -- tests pass (some may need updates due to new db parameter).
    Run a quick integration check:
    ```python
    python -c "
    from gathering.api.auth import TokenBlacklist, create_access_token, blacklist_token, is_token_blacklisted
    # Create a token
    token = create_access_token({'sub': 'test', 'email': 'test@test.com', 'role': 'user'})
    print(f'Token created: {token[:20]}...')
    # Verify not blacklisted
    assert not is_token_blacklisted(token), 'Should not be blacklisted'
    # Blacklist it
    blacklist_token(token)
    # Verify blacklisted
    assert is_token_blacklisted(token), 'Should be blacklisted'
    print('Token blacklist persistence test PASSED')
    "
    ```
  </verify>
  <done>In-memory _users_store replaced with auth.users queries. In-memory _token_blacklist replaced with TokenBlacklist class (LRU cache + PostgreSQL write-through). authenticate_user uses constant-time comparison with dummy hash. Auth events logged to audit.security_events. All auth functions accept optional db parameter for dependency injection.</done>
</task>

<task type="auto">
  <name>Task 2: Wire auth router and middleware to persistent auth</name>
  <files>
    gathering/api/routers/auth.py
    gathering/api/middleware.py
  </files>
  <action>
    **Step 1: Update gathering/api/routers/auth.py to pass DatabaseService.**

    The auth router currently imports functions from `gathering.api.auth` and calls them without a db parameter. Update the endpoints:

    - Add import: `from gathering.api.dependencies import DatabaseService`
    - In `login()` and `login_json()`: pass db to authenticate_user:
      ```python
      db = DatabaseService.get_instance()
      user = await authenticate_user(form_data.username, form_data.password, db=db)
      ```
    - In `register()`: pass db to get_user_by_email and create_user:
      ```python
      db = DatabaseService.get_instance()
      existing = await get_user_by_email(user_data.email, db=db)
      # ...
      user = await create_user(user_data, db=db)
      ```
    - In `logout()`: pass user_id to blacklist_token:
      ```python
      success = blacklist_token(token, user_id=current_user.sub)
      ```
    - In `get_current_user_info()`: update the import to use the updated `get_user_by_id` with db:
      ```python
      db = DatabaseService.get_instance()
      user = await get_user_by_id(current_user.sub, db=db)
      ```
    - Update `get_token_blacklist_stats()` -- no changes needed (function signature unchanged).

    **Step 2: Update login endpoints to log auth events on failure.**

    In both `login()` and `login_json()`, the `authenticate_user` function now handles audit logging internally (success and failure). No additional logging needed in the router.

    **Step 3: Update register endpoint to log registration events.**

    After successful user creation:
    ```python
    from gathering.api.auth import log_auth_event
    log_auth_event(db, "user_registered", user_id=user["id"], message=f"New user registered: {user_data.email}")
    ```

    **Step 4: Update gathering/api/middleware.py for audit logging on auth failures.**

    In `AuthenticationMiddleware.dispatch()`, when authentication fails (missing token, invalid token, expired token), log the event:

    - Add import: `from gathering.api.auth import log_auth_event`
    - Add import: `from gathering.api.dependencies import DatabaseService`
    - When returning 401 for missing token:
      ```python
      try:
          db = DatabaseService.get_instance()
          log_auth_event(db, "auth_missing_token", ip_address=request.client.host if request.client else None,
                        message=f"Missing auth token for {path}")
      except Exception:
          pass  # Don't block request processing for audit logging failures
      ```
    - When returning 401 for invalid/expired token, log similarly with event_type "auth_invalid_token".

    **Step 5: Ensure get_current_active_user dependency uses DB.**

    In `gathering/api/auth.py`, the `get_current_active_user()` function already calls `get_user_by_id()`. Since we updated `get_user_by_id()` to accept an optional db parameter and default to `DatabaseService.get_instance()`, this works without changes to the dependency function signature.

    **IMPORTANT:** Do NOT change the function signatures of FastAPI dependencies (`get_current_user`, `get_current_active_user`, `require_admin`) -- they are used as `Depends()` throughout the app. The db access happens internally via `DatabaseService.get_instance()`.
  </action>
  <verify>
    Run `pytest tests/test_auth.py -v` -- all tests pass.
    Run `pytest tests/ -k "auth" -v --timeout=30` -- any auth-related tests pass.
    Verify the app starts: `cd /home/loc/workspace/gathering && timeout 5 python -c "from gathering.api.main import app; print('App starts OK')" 2>&1`
  </verify>
  <done>Auth router passes DatabaseService to all auth functions. Login/register/logout endpoints use persistent database storage. Auth middleware logs security events on authentication failures. All auth operations are constant-time. Audit trail captures auth_success, auth_failure, user_registered, auth_missing_token, auth_invalid_token events.</done>
</task>

</tasks>

<verification>
1. Register a user via the API, verify the user exists in `auth.users` table
2. Restart the application (simulate by creating a new DatabaseService instance), verify the user still exists
3. Login with the registered credentials -- succeeds
4. Logout (blacklist token), verify token rejected
5. Restart -- token still rejected (blacklist persisted in `auth.token_blacklist`)
6. Login with non-existent email -- takes same time as valid email (constant-time)
7. Check `audit.security_events` table has entries for login success, login failure, registration
</verification>

<success_criteria>
- Users created via API exist in PostgreSQL auth.users and survive restart
- Token blacklist persists in auth.token_blacklist (LRU cache + DB write-through)
- authenticate_user is constant-time (dummy hash verification when user not found)
- Auth events logged to audit.security_events (auth_success, auth_failure, user_registered, auth_missing_token, auth_invalid_token)
- In-memory _users_store and _token_blacklist dict fully removed
- All existing auth tests pass
- API endpoint signatures unchanged (backward compatible)
</success_criteria>

<output>
After completion, create `.planning/phases/01-auth-security-foundation/01-02-SUMMARY.md`
</output>
