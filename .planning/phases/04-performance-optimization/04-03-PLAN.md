---
phase: 04-performance-optimization
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - gathering/events/event_bus.py
  - tests/test_event_bus_concurrency.py
autonomous: true

must_haves:
  truths:
    - "Rapid-fire event emissions (100+ events/second) are batched and deduplicated"
    - "The event bus does not spawn unbounded concurrent tasks under high load"
    - "Event ordering is preserved for each handler within a batch"
    - "Parallel handlers execute concurrently without data corruption"
    - "Duplicate events within a configurable window are suppressed"
  artifacts:
    - path: "gathering/events/event_bus.py"
      provides: "Batching, deduplication, and backpressure in EventBus.publish()"
      contains: "dedup"
    - path: "tests/test_event_bus_concurrency.py"
      provides: "Concurrency, ordering, dedup, and rapid-fire tests"
      contains: "test_rapid_fire"
  key_links:
    - from: "gathering/events/event_bus.py"
      to: "asyncio.Semaphore"
      via: "Concurrency limit on handler dispatch"
      pattern: "Semaphore"
    - from: "tests/test_event_bus_concurrency.py"
      to: "gathering/events/event_bus.py"
      via: "Import and exercise EventBus publish/subscribe"
      pattern: "from gathering.events"
---

<objective>
Add batching, deduplication, and backpressure to the event bus, then write comprehensive concurrency tests.

Purpose: PERF-04 and TEST-04 -- the event bus currently uses `asyncio.gather(*tasks)` with no concurrency limit, no deduplication, and no batching. Under 100+ events/second with 10 handlers, that is 1000+ unbounded concurrent tasks per second. This plan adds a semaphore-based concurrency limit, deduplication within a configurable time window, and tests proving correctness under concurrent load.

Output: Enhanced EventBus with backpressure and dedup; 5+ concurrency tests.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-performance-optimization/04-RESEARCH.md
@gathering/events/event_bus.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add deduplication and backpressure to EventBus</name>
  <files>gathering/events/event_bus.py</files>
  <action>
Enhance `gathering/events/event_bus.py` EventBus class with deduplication and concurrency limiting. Preserve backward compatibility -- existing publish() behavior (synchronous delivery to handlers) must not break.

1. **Add concurrency limiter** to `__init__()`:
   - Add `self._max_concurrent_handlers: int = 100` (configurable)
   - Add `self._handler_semaphore = asyncio.Semaphore(self._max_concurrent_handlers)`
   - This prevents unbounded task spawning under rapid-fire events.

2. **Add deduplication state** to `__init__()`:
   - Add `self._dedup_window: float = 1.0` (seconds, configurable)
   - Add `self._seen_events: dict[str, float] = {}` -- maps dedup_key to timestamp
   - Add `self._dedup_enabled: bool = True`

3. **Add dedup key computation method**:
   ```python
   def _dedup_key(self, event: Event) -> str:
       """Compute deduplication key for an event."""
       # Include type, source, circle, and a hash of data for specificity
       data_hash = hash(frozenset(
           (k, str(v)) for k, v in sorted(event.data.items())
       )) if event.data else 0
       return f"{event.type.value}:{event.source_agent_id}:{event.circle_id}:{data_hash}"
   ```

4. **Add dedup pruning method**:
   ```python
   def _prune_seen_events(self) -> None:
       """Remove expired entries from dedup cache to prevent memory growth."""
       import time
       now = time.monotonic()
       expired = [k for k, ts in self._seen_events.items() if (now - ts) > self._dedup_window * 2]
       for k in expired:
           del self._seen_events[k]
   ```

5. **Modify `publish()` method**:
   - BEFORE recording in history, check dedup:
     ```python
     import time
     # Deduplication check
     if self._dedup_enabled:
         dedup_key = self._dedup_key(event)
         now = time.monotonic()
         if dedup_key in self._seen_events:
             if (now - self._seen_events[dedup_key]) < self._dedup_window:
                 self._stats["events_deduplicated"] = self._stats.get("events_deduplicated", 0) + 1
                 return  # Duplicate within window, skip
         self._seen_events[dedup_key] = now
         # Periodic cleanup (every 1000 events)
         if self._stats["events_published"] % 1000 == 0:
             self._prune_seen_events()
     ```
   - Keep the existing history append and subscriber dispatch logic
   - WRAP the `asyncio.gather(*tasks)` call with semaphore-limited execution:
     ```python
     # Execute handlers with concurrency limit
     if tasks:
         limited_tasks = [self._limited_invoke(t) for t in tasks]
         await asyncio.gather(*limited_tasks, return_exceptions=True)
         self._stats["events_delivered"] += len(tasks)
     ```
   - Note: `tasks` list currently contains coroutines from `_safe_invoke()`. The limited wrapper should be:
     ```python
     async def _limited_invoke(self, coro) -> None:
         """Execute handler with semaphore-based concurrency limit."""
         async with self._handler_semaphore:
             await coro
     ```
   - Wait -- `_safe_invoke` returns a coroutine. We need to change the approach slightly. Instead of wrapping the coroutine, modify `_safe_invoke` to acquire the semaphore:
     - In `_safe_invoke()`, add `async with self._handler_semaphore:` around the handler invocation.
     - This is simpler and keeps the existing `asyncio.gather(*tasks)` pattern.

6. **Add configuration methods**:
   ```python
   def configure(self, max_concurrent_handlers: int = None, dedup_window: float = None, dedup_enabled: bool = None) -> None:
       """Configure event bus parameters."""
       if max_concurrent_handlers is not None:
           self._max_concurrent_handlers = max_concurrent_handlers
           self._handler_semaphore = asyncio.Semaphore(max_concurrent_handlers)
       if dedup_window is not None:
           self._dedup_window = dedup_window
       if dedup_enabled is not None:
           self._dedup_enabled = dedup_enabled
   ```

7. **Update `_stats`** dict initialization to include `"events_deduplicated": 0`.

8. **Update `reset()`** method (if it exists) to also clear `_seen_events` and reset the semaphore.

9. **IMPORTANT backward compatibility**: The dedup is on by default with a 1-second window. For tests that publish many identical events and expect all to be delivered, they can call `bus.configure(dedup_enabled=False)` or `bus._dedup_enabled = False`. Alternatively, make dedup check only trigger when the SAME event type+data+source is published within the window -- truly distinct events (different data) always pass through.
  </action>
  <verify>
    - `python -c "from gathering.events.event_bus import EventBus; bus = EventBus(); bus.reset(); print('import ok')"` succeeds
    - `python -c "from gathering.events.event_bus import EventBus; bus = EventBus(); bus.reset(); assert hasattr(bus, '_handler_semaphore'); assert hasattr(bus, '_seen_events'); print('attributes exist')"` succeeds
    - `python -m pytest tests/ -x -q --timeout=30 -k 'not test_event_bus_concurrency' 2>&1 | tail -20` -- existing tests pass
  </verify>
  <done>EventBus.publish() deduplicates rapid-fire identical events within a 1-second window. Handler dispatch is limited to 100 concurrent tasks via asyncio.Semaphore. Dedup cache is periodically pruned to prevent memory growth. All changes are backward compatible.</done>
</task>

<task type="auto">
  <name>Task 2: Write event bus concurrency tests</name>
  <files>tests/test_event_bus_concurrency.py</files>
  <action>
Create `tests/test_event_bus_concurrency.py` with comprehensive concurrency tests for the event bus. These tests prove PERF-04 (batching/dedup under load) and TEST-04 (concurrency correctness).

Use `pytest.mark.asyncio` on all tests. Import `EventBus`, `Event`, `EventType` from `gathering.events`.

**Test 1: `test_parallel_handlers_no_race_condition`**
- Subscribe 10 handlers to TASK_COMPLETED, each incrementing a shared counter under asyncio.Lock
- Publish 1 event
- Assert counter == 10 (all handlers ran)
- Proves: concurrent handlers execute without data corruption

**Test 2: `test_rapid_fire_does_not_exhaust_memory`**
- Subscribe 1 handler that appends event.data["seq"] to a list
- Disable dedup (`bus.configure(dedup_enabled=False)`) since events have unique data
- Publish 200 events rapidly with unique data ({"seq": i})
- Assert len(received) == 200
- Assert no asyncio tasks leaked (check with asyncio.all_tasks before/after)
- Proves: rapid-fire publishing handles load without spawning unbounded tasks

**Test 3: `test_event_ordering_preserved`**
- Subscribe 1 handler that appends event.data["seq"] to a list
- Disable dedup
- Publish 50 events sequentially with data={"seq": i}
- Assert order == list(range(50))
- Proves: per-handler event ordering is maintained

**Test 4: `test_deduplication_suppresses_identical_events`**
- Subscribe 1 handler that appends to a list
- Ensure dedup is enabled (default)
- Publish the SAME event (same type, same data, same source_agent_id) 10 times rapidly
- Assert handler called only once (dedup suppressed 9)
- Proves: deduplication works for truly identical rapid-fire events

**Test 5: `test_dedup_allows_distinct_events`**
- Subscribe 1 handler
- Ensure dedup is enabled
- Publish 10 events with DIFFERENT data ({"id": i}) rapidly
- Assert handler called 10 times (distinct data = no dedup)
- Proves: dedup does not suppress semantically different events

**Test 6: `test_semaphore_limits_concurrent_handlers`**
- Create bus with `bus.configure(max_concurrent_handlers=3)`
- Subscribe 10 handlers that each `await asyncio.sleep(0.01)` and track max concurrent via a counter
- Publish 1 event
- Assert max concurrent never exceeded 3
- Proves: semaphore backpressure works

**Test 7: `test_handler_error_does_not_block_others`**
- Subscribe 3 handlers: first raises Exception, second and third append to list
- Publish 1 event
- Assert list has 2 entries (error handler isolated)
- Proves: error isolation under concurrent execution

**Setup/teardown pattern:**
```python
@pytest.fixture(autouse=True)
def reset_event_bus():
    bus = EventBus()
    bus.reset()
    yield bus
    bus.reset()
```

**Important**: Each test must reset the EventBus singleton to avoid state leaking between tests. Use `bus.reset()` in fixture setup and teardown.
  </action>
  <verify>
    - `python -m pytest tests/test_event_bus_concurrency.py -v --timeout=30 2>&1 | tail -30` -- all 7 tests pass
    - `python -m pytest tests/ -x -q --timeout=30 2>&1 | tail -20` -- full suite passes
  </verify>
  <done>7 event bus concurrency tests pass: parallel handler safety, rapid-fire memory safety, event ordering, dedup suppression, dedup pass-through for distinct events, semaphore concurrency limiting, and error isolation.</done>
</task>

</tasks>

<verification>
- EventBus has _handler_semaphore and _seen_events attributes
- Dedup suppresses identical rapid-fire events
- Semaphore limits concurrent handler execution
- All 7 concurrency tests pass
- All existing tests pass (no regressions from dedup or semaphore changes)
</verification>

<success_criteria>
1. `from gathering.events.event_bus import EventBus` imports with dedup and semaphore attributes
2. `python -m pytest tests/test_event_bus_concurrency.py -v --timeout=30` shows 7 passing tests
3. `python -m pytest tests/ -x -q --timeout=30` full suite passes
4. EventBus.publish() deduplicates identical events within 1-second window
5. Handler concurrency bounded by semaphore (default: 100)
</success_criteria>

<output>
After completion, create `.planning/phases/04-performance-optimization/04-03-SUMMARY.md`
</output>
